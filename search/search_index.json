{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Introduction","text":"<p>The content of this repository can also be viewed here:</p> <p>https://bids-standard.github.io/bids-examples/</p>"},{"location":"index.html#bids-examples","title":"bids-examples","text":"<p>This repository contains a set of BIDS-compatible datasets with empty raw data files. These datasets can be useful to:</p> <ol> <li>write lightweight software tests</li> <li>serve as an example on how a BIDS dataset can be structured</li> </ol> <p>ALL RAW DATA FILES IN THIS REPOSITORY ARE EMPTY!</p> <p>However for some of the data, the headers containing the metadata are still intact. (For example the NIfTI headers for <code>.nii</code> files, the BrainVision data headers for <code>.vhdr</code> files, or the OME-XML headers for <code>.ome.tif</code> files.)</p> <p>Headers are intact for the following datasets:</p> <ul> <li><code>synthetic</code></li> <li>Most EEG or iEEG data in BrainVision format (e.g., <code>eeg_matchingpennies</code>)</li> </ul>"},{"location":"index.html#validating-bids-examples","title":"Validating BIDS examples","text":"<p>The next three sections mention a few details on how the <code>bids-examples</code> can be validated using <code>bids-validator</code>.</p> <p>For general information on the <code>bids-validator</code>, including installation and usage, see the bids-validator README file.</p>"},{"location":"index.html#validating-individual-examples","title":"Validating individual examples","text":"<p>Since all raw data files in this repository are empty, the <code>bids-validator</code> must to be configured to not report empty data files as errors. (See more on bids-validator configuration in the bids-validator README.)</p> <p>Just run the validator as follows (using the <code>eeg_matchingpennies</code> dataset as an example, and assuming you are in a command line at the root of the <code>bids-examples</code> repository):</p> <p><code>bids-validator eeg_matchingpennies --config.ignore=99</code></p> <p>The <code>--config.ignore=99</code> \"flag\" tells the bids-validator to ignore empty data files rather than to report the \"empty file\" error .</p> <p>For datasets that contain NIfTI <code>.nii</code> files, you also need to add the <code>ignoreNiftiHeaders</code> flag to the <code>bids-validator</code> call, to suppress the issue that NIfTI headers are not found.</p> <p>For example:</p> <p><code>bids-validator ds003 --config.ignore=99 --ignoreNiftiHeaders</code></p>"},{"location":"index.html#validating-all-examples","title":"Validating all examples","text":"<p>If you want to validate all examples in one go, you can use the <code>run_tests.sh</code> script that is provided in this repository. This script makes use of the <code>bidsconfig.json</code> configuration file for the <code>bids-validator</code>, and appropriately handles some special case examples (see Validator Exceptions).</p> <p>Simply run <code>bash run_tests.sh</code> in a command line from the root of the <code>bids-examples</code> repository.</p>"},{"location":"index.html#validator-exceptions","title":"Validator exceptions","text":"<p>Some datasets may include a custom <code>.bids-validator-config.json</code> to ignore errors generated from idiosyncrasies of the datasets as they existed on creation.</p> name errors ignored genetics_ukbb SliceTiming values for tasks is larger than given TR, EchoTime1 and EchoTime2 are not provided for any of the phasediff files. <p>Other datasets may include a <code>.SKIP_VALIDATION</code> file, to skip the validation with the continuous integration service. This is useful for datasets that cannot pass at the moment due to lack of coverage in the bids-validator.</p> <p>Note however, that the <code>.SKIP_VALIDATION</code> file only impacts the continuous integration service, or validation when run with the <code>run_tests.sh</code> script (see Validating all examples). This file does not have any effect when running <code>bids-validator</code> from custom scripts, the web-based validator, docker, or from the command line.</p> name why skipped ds000001-fmriprep lack of coverage for \"derivatives\" in <code>bids-validator</code>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>We are happy to receive contributions in the form of:</p> <ul> <li>updates to existing examples, or the dataset index</li> <li>new examples</li> <li>only if they cover aspects that are currently not covered by existing     examples</li> <li>only if a maintainer can be found for this dataset</li> <li>suggestions on how to improve the bids-examples repository</li> </ul> <p>For more information, please see our CONTRIBUTING.md file or open a new GitHub Issue and ask us directly.</p>"},{"location":"index.html#dataset-index","title":"Dataset index","text":""},{"location":"index.html#asl","title":"ASL","text":"name description datatypes suffixes link to full data maintained by asl001 T1w, asl (GE, PCASL, 3D_SPIRAL), m0scan within timeseries anat, perf T1w, asl, aslcontext, asllabeling link @patsycle asl002 T1w, asl (Philips, PCASL, 2D_EPI), m0scan as separate scan anat, perf T1w, asl, aslcontext, asllabeling, m0scan link @patsycle asl003 T1w, asl (Siemens, PASL, multiTI), M0scan as separate scan anat, perf T1w, asl, aslcontext, asllabeling, m0scan link @patsycle asl004 T1w, asl (Siemens, PCASL, multiPLD with pepolar), m0scan separate scans with pepolar appraoch anat, fmap, perf T1w, asl, aslcontext, asllabeling, m0scan link @patsycle asl005 T1w, asl (Siemens, PCASL, singleTI, 3D_GRASE), m0scan as separate scan anat, perf T1w, asl, aslcontext, asllabeling, m0scan link @patsycle"},{"location":"index.html#eeg","title":"EEG","text":"name description datatypes suffixes link to full data maintained by eeg_cbm Rest EEG. European Data Format (.edf) eeg channels, eeg, events, scans n/a @cpernet eeg_ds003645s_hed_demo Shows usage of Hierarchical Event Descriptor (HED) in tsv files eeg channels, eeg, events, participants, etc. link @VisLab eeg_ds003645s_hed_library HED annotation using HED library vocabularies (schema). eeg channels, eeg, events link @VisLab eeg_face13 Deconstructing the early visual electrocortical response to face and house stimuli. EDF format eeg channels, coordsystem, eeg, electrodes, events n/a @andesha eeg_matchingpennies Offline data of BCI experiment decoding left vs. right hand movement. BrainVision data format (.eeg, .vhdr, .vmrk) eeg channels, eeg, events link @sappelhoff eeg_rishikesh Mind wandering experiment. EEG data in Biosemi (.bdf) format eeg channels, eeg, events link @arnodelorme"},{"location":"index.html#ieeg","title":"iEEG","text":"name description datatypes suffixes link to full data maintained by ieeg_epilepsyNWB multiple sessions, tutorial \u2014 derivative dataset of <code>ieeg_epilepsy</code> showcasing the NWB file format alternative anat, ieeg T1w, channels, coordsystem, electrodes, events, ieeg, scans link @TheChymera ieeg_epilepsy multiple sessions, tutorial anat, ieeg T1w, channels, coordsystem, electrodes, events, ieeg, scans link @ftadel ieeg_epilepsy_ecog multiple sessions, tutorial anat, ieeg T1w, channels, coordsystem, electrodes, events, ieeg, photo, scans link @ftadel ieeg_filtered_speech recordings of three seizures ieeg channels, coordsystem, electrodes, events, ieeg, photo n/a @choldgraf ieeg_motorMiller2007 Cue-based hand &amp; tongue movement data ieeg channels, coordsystem, electrodes, events, ieeg n/a @dorahermes ieeg_visual Stimulus dependence of gamma oscillations in human visual cortex anat, ieeg T1w, channels, coordsystem, electrodes, events, ieeg n/a @dorahermes ieeg_visual_multimodal n/a anat, fmap, func, ieeg T1w, bold, channels, coordsystem, electrodes, epi, events, ieeg, sbref n/a @irisgroen"},{"location":"index.html#meg","title":"MEG","text":"name description datatypes suffixes link to full data maintained by ds000117 A multi-subject, multi-modal human neuroimaging dataset of 19 subjects on a MEG visual task anat, beh, dwi, fmap, func, meg T1w, beh, bold, channels, coordsystem, dwi, events, headshape, magnitude1, magnitude2, meg, phasediff, scans link @RikHenson ds000246 Auditory dataset used for Brainstorm\u2019s general online tutorial anat, meg ChannelGroupSet, ClassFile, MarkerFile, T1w, channels, coordsystem, default, headshape, meg, params, photo, processing, scans link @guiomar ds000247 Five minutes, eyes-open, resting-state MEG data from 5 subjects. This is a sample from The Open MEG Archive (OMEGA). anat, meg ClassFile, T1w, bad, channels, coordsystem, default, headshape, meg, params, processing, scans link @guiomar ds000248 MNE sample data: Data with visual and auditory stimuli anat, meg FLASH, T1w, channels, coordsystem, events, meg, scans link @agramfort"},{"location":"index.html#microscopy","title":"Microscopy","text":"name description datatypes suffixes link to full data maintained by micr_SEM Example SEM dataset in PNG format with 1 sample imaged over 2 sessions micr SEM, photo, samples, sessions link @jcohenadad micr_SEMzarr Example SEM dataset in PNG and OME-ZARR format with 1 sample imaged over 2 sessions micr SEM, samples, sessions n/a @TheChymera micr_SPIM Example SPIM dataset in OME-TIFF format with 2 samples from the same subject with 4 chunks each micr SPIM, photo, samples link @jcohenadad"},{"location":"index.html#motion","title":"Motion","text":"name description datatypes suffixes link to full data maintained by motion_dualtask older and younger participants walking while performing discrimination task eeg, motion channels, eeg, events, motion, scans n/a @sjeung motion_spotrotation participants rotated heading using full-body motion or joystick eeg, motion channels, coordsystem, eeg, electrodes, events, motion, scans link @sjeung motion_systemvalidation Example dataset of two different motion captured system recorded almost simultaneously, but no brain data motion channels, motion, scans link @JuliusWelzel"},{"location":"index.html#mri","title":"MRI","text":"name description datatypes suffixes link to full data maintained by 7t_trt n/a anat, fmap, func T1map, T1w, bold, magnitude1, magnitude2, phasediff, physio, scans, sessions link n/a ds000117 A multi-subject, multi-modal human neuroimaging dataset of 19 subjects on a MEG visual task anat, beh, dwi, fmap, func, meg T1w, beh, bold, channels, coordsystem, dwi, events, headshape, magnitude1, magnitude2, meg, phasediff, scans link @RikHenson ds001 single task, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds002 multiple tasks, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds003 single task, single run anat, func T1w, bold, events, inplaneT2 link n/a ds005 single task, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds006 single task, multiple sessions, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds007 single task, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds008 multiple tasks, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds009 multiple tasks, multiple runs anat, func T1w, bold, events, inplaneT2, scans link n/a ds011 multiple tasks, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds051 multiple tasks, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds052 multiple tasks, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds101 single task, multiple runs anat, func T1w, bold, events link n/a ds102 single task, multiple runs anat, func T1w, bold, events link n/a ds105 single task, multiple runs anat, func T1w, bold, events link n/a ds107 single task, multiple runs anat, func T1w, bold, events link n/a ds108 single task, multiple runs anat, func T1w, bold, events link n/a ds109 multiple tasks, multiple runs anat, func T1w, bold, events link n/a ds110 single task, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds113b forrest gump watching, multiple sessions, multiple runs func bold, events link n/a ds114 multiple tasks, multiple runs anat, dwi, func T1w, bold, dwi, events link n/a ds116 multiple tasks, multiple runs anat, func T1w, bold, events, inplaneT2 link n/a ds210 multiple tasks, multiple runs func bold, physio link n/a eeg_rest_fmri Resting state with simultaneous fMRI. BrainVision data format (.eeg, .vhdr, .vmrk) anat, dwi, eeg, func T1w, bold, dwi, eeg n/a @cpernet genetics_ukbb multiple tasks, T1w, DTI, BOLD, genetic info anat, dwi, fmap, func FLAIR, T1w, bold, dwi, events, info, magnitude1, phasediff n/a @cpernet ieeg_visual_multimodal n/a anat, fmap, func, ieeg T1w, bold, channels, coordsystem, electrodes, epi, events, ieeg, sbref n/a @irisgroen synthetic A synthetic dataset anat, beh, func T1w, beh, bold, events, physio, scans, sessions, stim n/a @effigies"},{"location":"index.html#nirs","title":"NIRS","text":"name description datatypes suffixes link to full data maintained by fnirs_automaticity 24 subjects performing (non-)automatic finger tapping and foot stepping nirs channels, coordsystem, events, nirs, optodes, practicelogbook, scans link @robertoostenveld fnirs_tapping Example fNIRS measurement with three conditions from five subjects nirs channels, coordsystem, events, nirs, optodes, scans link @rob_luke"},{"location":"index.html#pet","title":"PET","text":"name description datatypes suffixes link to full data maintained by pet001 T1w, PET, blood anat, pet T1w, blood, pet n/a @mnoergaard pet002 T1w, PET anat, pet T1w, pet link @mnoergaard pet003 T1w, PET, blood anat, pet T1w, blood, pet n/a @mnoergaard pet004 PET, blood pet blood, pet n/a @mnoergaard pet005 T1w, PET anat, pet T1w, events, pet n/a @mnoergaard"},{"location":"index.html#qmri","title":"qMRI","text":"name description datatypes suffixes link to full data maintained by qmri_irt1 Inversion Recovery T1 mapping anat IRT1 <code>not publicly availabe</code> @agahkarakuzu qmri_megre Multi-Echo Gradient-Echo for T2star mapping. anat MEGRE <code>not publicly availabe</code> @agahkarakuzu qmri_mese Multi-Echo Spin-Echo for T2 or Myelin Water Fraction (MWF) mapping. anat MESE <code>not publicly availabe</code> @agahkarakuzu qmri_mp2rage MP2RAGE for T1 mapping anat MP2RAGE, defacemask link @Gilles86 qmri_mp2rageme Multi-echo MP2RAGE anat, fmap MP2RAGE, TB1map link @Gilles86 qmri_mpm Multi-parametric mapping for R1, R2star, MTsat and PD mapping anat, fmap MPM, RB1COR, TB1EPI, magnitude1, magnitude2, phasediff link @ChristophePhillips qmri_mtsat Example dataset for T1 and MTsat mapping. Includes a double-angle B1+ mapping example. anat, fmap MTS, TB1DAM link @agahkarakuzu qmri_qsm Chimap using fast QSM anat T1w <code>not publicly availabe</code> @agahkarakuzu qmri_sa2rage Fast B1+ mapping using SA2RAGE fmap TB1SRGE <code>not publicly availabe</code> @agahkarakuzu qmri_tb1tfl B1+ mapping with TurboFLASH readout. fmap TB1TFL <code>not publicly availabe</code> @agahkarakuzu qmri_vfa Variable Flip Angle T1 mapping. Includes an Actual Flip Angle (AFI) B1+ mapping example. anat, fmap TB1AFI, VFA link @agahkarakuzu"},{"location":"CONTRIBUTING.html","title":"Welcome to the bids-examples repository!","text":"<p>Below, we note down some helpful information for contributors.</p>"},{"location":"CONTRIBUTING.html#what-does-a-dataset-maintainer-do","title":"What does a dataset maintainer do?","text":"<p>A maintainer of a dataset is responsible for keeping the dataset up to date, and making sure that all updates are mirrored between the dataset with full size raw data (for example, as hosted on OpenNeuro), and the bids-example dataset with 0kb size (empty) raw data.</p> <p>Typically an update to a BIDS dataset may be required, if the bids-validator is updated and gets an increased coverage of BIDS aspects to validated. In such cases, the new validator may reveal bugs that have gone undetected in the previous validation.</p>"},{"location":"CONTRIBUTING.html#why-do-we-only-host-truncated-data-with-0kb-size","title":"Why do we only host truncated data with 0kb size?","text":"<p>The datasets in the bids-examples repository are intended for lightweight testing purposes only. Keeping the data volume low allows for fast download times and a low memory footprint in the tests these data are used for.</p> <p>Admittedly, these advantages come at the expense of reduced testing functionality. Because the tests cannot go beyond very basic checks of filenames and directory structures.</p> <p>To provide a remedy for that, we provide some datasets with intact data headers, see the Dataset Index Table.</p>"},{"location":"CONTRIBUTING.html#how-to-truncate-data-files-to-0kb","title":"How to truncate data files to 0kb","text":"<p>You can always write a custom script in your favourite programming language, but if you need a quick and simple way and have access to a unix based machine (e.g., OSX, Linux), you can use the <code>find</code> command line tool:</p> <pre><code>find &lt;path_to_ds&gt; -type f -name '*.fif' -exec truncate -s 0 {} +\n</code></pre> <p>which means:</p> <ul> <li>in this directory <code>&lt;path_to_ds&gt;</code></li> <li>... find everything of type \"file\" (or specify <code>d</code> for directory, ...)</li> <li>[optional] ... use <code>-name</code> with wildcard <code>*</code> to match to particular file types</li> <li>... for each file, execute something</li> <li>... namely, truncate the file</li> <li>... to size 0</li> <li><code>{}</code> is where a file name is put automatically (do not modify it)</li> <li><code>+</code> means, this is performed not file-wise but with a bunch of files at once.     Could also be <code>\\;</code> to have it one after the other</li> </ul>"},{"location":"CONTRIBUTING.html#how-to-generate-the-tables-in-the-readme","title":"How to generate the tables in the readme","text":"<p>Note that these steps must be executed whenever a new dataset is added to the repository.</p> <ol> <li>Edit the <code>dataset_listing.tsv</code> file to add or update datasets from the table.</li> <li>Install all the necessary dependencies: <code>pip install -r tools/requirements.txt</code></li> <li>Then run the script: <code>python tools/print_dataset_listing.py</code></li> <li>Finally, <code>git commit</code> all changes and <code>git push</code> them to your remote (for example when you are working on a Pull Request)</li> </ol>"},{"location":"CONTRIBUTING.html#how-to-make-a-release","title":"How to make a release","text":"<p>We release <code>bids-examples</code> in sync with <code>bids-specification</code>.</p> <ol> <li>Make sure your local repository is up to date: <code>git fetch upstream</code>    (this assumes you have the <code>bids-standard/bids-examples</code> repository     configured as a git remote called \"upstream\")</li> <li>Tag the <code>master</code> branch: <code>git tag -a -m \"X.X.X\" X.X.X upstream/master</code>    (replace <code>X.X.X</code> with the version to be released)</li> <li>Push the tag upstream: <code>git push upstream X.X.X</code></li> <li>Create a GitHub release using the new tag. Fill the title of the release    with the name of the tag. Fill the description of the release with a sentence like <p>\"Microscopy\" BEP was merged into BIDS-specification (2022-02-15).</p> </li> <li>You are done!</li> </ol>"}]}