{
    "TaskName": "haririhammer",
    "Manufacturer": "CTF",
    "PowerLineFrequency": 60,
    "SamplingFrequency": 1200.0,
    "SoftwareFilters": "n/a",
    "RecordingDuration": 624.9991666666666,
    "RecordingType": "continuous",
    "DewarPosition": "upright",
    "DigitizedLandmarks": true,
    "DigitizedHeadPoints": false,
    "MEGChannelCount": 272,
    "MEGREFChannelCount": 272,
    "EEGChannelCount": 0,
    "EOGChannelCount": 0,
    "ECGChannelCount": 0,
    "EMGChannelCount": 0,
    "MiscChannelCount": 82,
    "TriggerChannelCount": 1,
    "InstitutionName": "National Institute of Mental Health",
    "InstitutionAddress": "9000 Rockville Pike, Bethesda, MD 20892",
    "ManufacturersModelName": "CTF-275",
    "SoftwareVersions": "Acq 6.1.14-beta-el6_8.x86_64-20180116-3847",
    "TaskDescription": "Participants view an image (either a face or a shape) then a pair of images (a pair of faces or a pair of shapes). They are asked to match the faces according to emotion (happy or sad) and match the shapes according to shape (although horizontal/vertical orientation may vary). This task is modeled after the Amygdala Reactivity Paradigm described here: https://www.haririlab.com/methods/amygdala.html.",
    "Instructions": "'This is a matching task. You will see an image, followed by a brief delay, then two simultaneous images. Match the first image to the corresponding image in the pair. For faces, match the emotion displayed. For shapes, match the corresponding shape. Press the left or right button to indicate the match.'",
    "CogAtlasID": "https://www.cognitiveatlas.org/task/id/trm_4e8a0dd29ec7b/",
    "DeviceSerialNumber": "M015_1609",
    "HeadCoilFrequency": [
        435.0,
        465.0,
        52.0
    ],
    "ECOGChannelCount": 0,
    "SEEGChannelCount": 0,
    "ContinuousHeadLocalization": false,
    "SubjectArtefactDescription": "n/a",
    "EEGPlacementScheme": "n/a",
    "CapManufacturer": "n/a",
    "CapManufacturersModelName": "n/a",
    "EEGReference": "n/a"
}